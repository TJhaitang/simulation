{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "class estiminator:\n",
    "    def __init__(self,n_features,s=0,L=0):\n",
    "        self.params=np.zeros(n_features)\n",
    "        self.n_features=n_features\n",
    "        self.s=s\n",
    "        self.L=L\n",
    "    \n",
    "    @abstractmethod\n",
    "    def fit(self, samples_packs,s=0,L=0):\n",
    "        pass\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "\n",
    "# 该估计器仅使用目标模型的样本数据进行lasso估计\n",
    "class T_lasso(estiminator):\n",
    "    def __init__(self, n_features=0,s=0,L=0,instance=None):\n",
    "        if instance is not None:\n",
    "            super(T_lasso, self).__init__(instance.n_features,instance.s,instance.L)\n",
    "        else:\n",
    "            assert n_features>0 and s>0 and L>0\n",
    "            super(T_lasso, self).__init__(n_features,s,L)\n",
    "        \n",
    "    def fit(self,samples_packs,s=0,L=0):\n",
    "        from sklearn.linear_model import Lasso\n",
    "        lambda1=0.01\n",
    "        X=samples_packs[0].getX()\n",
    "        y=samples_packs[0].getY()\n",
    "        lasso=Lasso(alpha=lambda1)\n",
    "        lasso.fit(X,y)\n",
    "        #保留绝对值前s大个-?有意义吗？\n",
    "        # lasso.coef_[np.argsort(np.abs(lasso.coef_))[:-self.s]] = 0\n",
    "        self.params=lasso.coef_\n",
    "        return lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Our_method(estiminator):\n",
    "    def __init__(self, n_features=0,s=0,L=0,instance=None):\n",
    "        if instance is not None:\n",
    "            super(Our_method, self).__init__(instance.n_features,instance.s,instance.L)\n",
    "        else:\n",
    "            assert n_features>0 and s>0 and L>0\n",
    "            super(Our_method, self).__init__(n_features,s,L)\n",
    "      \n",
    "    #这个方法没有用到，目的是方便使用梯度下降等方法，将更新方法放到模型里面去  \n",
    "    def likelihood(self, beta, delta, samples_pack):\n",
    "        beta=beta+delta\n",
    "        X=samples_pack.getX()\n",
    "        y=samples_pack.getY()\n",
    "        # 似然函数为高斯分布\n",
    "        return -np.sum((y-np.dot(X,beta))**2)\n",
    "    \n",
    "    #更新beta\n",
    "    #输入：delta:辅助模型与目标模型的回归系数差矩阵，v:辅助模型是否被选择的向量，samples_packs:样本数据\n",
    "    # 优化问题：argmax_{beta} l_0(beta)+sum_{k=1}^{K}(l_k(beta,delta[k])-lambda*||delta||_2)*v[k]\n",
    "    def update_beta(self, delta, v, samples_packs):\n",
    "        # 对于线性模型，该问题有显式解\n",
    "        # 该显式解为beta=(x0^T*x0+sum_{k=1}^{K}v[k]*xk^T*xk-lambda*E)^{-1}*(x0^T*y0+sum_{k=1}^{K}v[k]*xk^T*yk-sum_{k=1}^{K}v[k]*xk^T*xk*delta[k])\n",
    "        # x0,y0为目标模型的样本数据\n",
    "        # xk,yk为第k个辅助模型的样本数据\n",
    "        \n",
    "        #mat1=x0^T*x0+sum_{k=1}^{K}v[k]*xk^T*xk-lambda*E\n",
    "        lamb=0.001\n",
    "        mat1=np.dot(samples_packs[0].getX().T,samples_packs[0].getX())\n",
    "        # mat1-=lamb*np.eye(len(samples_packs[0].getX()[0]))\n",
    "        for i in range(len(samples_packs)-1):\n",
    "            if v[i]==1:\n",
    "                mat1+=np.dot(samples_packs[i+1].getX().T,samples_packs[i+1].getX())\n",
    "        #mat2=x0^T*y0+sum_{k=1}^{K}v[k]*xk^T*yk\n",
    "        mat2=np.dot(samples_packs[0].getX().T,samples_packs[0].getY())\n",
    "        for i in range(len(samples_packs)-1):\n",
    "            if v[i]==1:\n",
    "                mat2+=np.dot(samples_packs[i+1].getX().T,samples_packs[i+1].getY())\n",
    "        #mat3=sum_{k=1}^{K}v[k]*xk^T*xk*delta[k]\n",
    "        mat3=np.zeros(len(samples_packs[0].getX()[0]))\n",
    "        for i in range(len(samples_packs)-1):\n",
    "            if v[i]==1:\n",
    "                mat3+=np.dot(samples_packs[i+1].getX().T,np.dot(samples_packs[i+1].getX(),delta[i]))\n",
    "        beta=np.dot(np.linalg.inv(mat1),mat2-mat3)\n",
    "        return beta\n",
    "    \n",
    "    #更新delta\n",
    "    #输入：beta:当前beta，sample_pack:该模型的样本数据\n",
    "    #输出：更新后的delta_k\n",
    "    def update_delta_k(self,beta,sample_pack):  \n",
    "        # 该优化问题为: argmin_{delta_k} ||y_k-x_k*beta-x_k*delta_k||_2^2+lambda*||delta_k||_2\n",
    "        # 该问题好像没有显式解，但函数是凸函数，可以使用梯度下降法求解\n",
    "        # 目标函数在0处不可导\n",
    "        # -?先比较lambda与||X.T*y||_2的大小，如果lambda大，则delta_k=0\n",
    "        # -?使用IHT迭代算法求解\n",
    "        lamb=0.1#-?\n",
    "        X=sample_pack.getX()\n",
    "        y=sample_pack.getY()\n",
    "        y=y-np.dot(X,beta)#优化delta\n",
    "        if lamb>=np.linalg.norm(np.dot(X.T,y)):\n",
    "            return np.zeros(len(X[0]))\n",
    "        else:\n",
    "            #使用IHT方法迭代求解\n",
    "            #先测试一下\n",
    "            #L是X的最大奇异值\n",
    "            U,sigma,VT=np.linalg.svd(X)\n",
    "            Lipschitz=sigma[0]*sigma[0]\n",
    "            # print(Lipschitz)\n",
    "            max_iter=1000\n",
    "            #岭回归结果作为初值\n",
    "            delta=np.dot(np.linalg.inv(np.dot(X.T,X)+lamb*np.eye(len(X[0]))),np.dot(X.T,y))\n",
    "            delta2=delta+0\n",
    "            for i in range(max_iter):\n",
    "                #计算梯度\n",
    "                grad=np.dot(X.T,np.dot(X,delta)-y)\n",
    "                b=delta-1/Lipschitz*grad\n",
    "                # assert 2*lamb/Lipschitz<np.linalg.norm(b)#初始条件保证不可能进这里\n",
    "                delta=(1-lamb/(Lipschitz*np.linalg.norm(b)))*b\n",
    "                if np.linalg.norm(delta-delta2)<0.0001:\n",
    "                    break\n",
    "                delta2=delta\n",
    "            return delta\n",
    "        \n",
    "    \n",
    "    # 非iid分布式迁移学习与数据源选择\n",
    "    # delta[k]=beta[k]-beta[0] 为第k个辅助模型与目标模型的回归系数差\n",
    "    # 上述参数均为n_features维向量\n",
    "    # v[k]属于{0,1},为第k个辅助模型是否被选择\n",
    "    # 优化问题：argmax_{beta,delta[k],v[k]} l_0(beta)+sum_{k=1}^{K}(l_k(beta,delta[k])-lambda*||delta||_2)*v[k]\n",
    "    # s.t. ||v||_0=L\n",
    "    # l_k为模型的似然函数，当前模型为线性模型，似然函数为高斯分布\n",
    "    # 使用两步迭代算法求解\n",
    "    # 第一步：固定v[k]，求解beta[0],delta[k]\n",
    "    # 求解beta与delta时也使用两步迭代算法\n",
    "    # 第二步：固定beta[0],delta[k]，求解v[k]\n",
    "    # 重复以上两步直到收敛（或达到最大迭代次数）\n",
    "    # -?没有设置收敛条件，目前仅仅设置了最大迭代次数\n",
    "    # 输入：samples_packs:样本数据，s:目标模型稀疏度，L:选定的辅助模型个数\n",
    "    def fit(self, samples_packs,s=0,L=0,coef_list=[]):\n",
    "        #如果model_num==0,则直接使用目标模型的样本数据进行lasso估计\n",
    "        if s==0:\n",
    "            s=self.s\n",
    "        if L==0:\n",
    "            L=self.L\n",
    "        model_num=len(samples_packs)-1\n",
    "        if model_num==0:\n",
    "            lasso=Lasso(alpha=0.01)\n",
    "            lasso.fit(samples_packs[0].getX(),samples_packs[0].getY())\n",
    "            #保留绝对值前s大个-?有意义吗？\n",
    "            self.params=lasso.coef_\n",
    "            return lasso.coef_,[],[],[]\n",
    "        # 初始化参数\n",
    "        # -?第一次迭代时使用全部模型,v=[1,1,1,1,...]\n",
    "        #计算程序运行时间\n",
    "        start_time=time.time()\n",
    "        times=[]\n",
    "        times.append(time.time()-start_time)\n",
    "        \n",
    "        v=np.zeros(len(samples_packs)-1)\n",
    "        v1=np.zeros(len(samples_packs)-1)\n",
    "        # beta为目标模型的回归系数\n",
    "        beta=np.zeros(len(samples_packs[0].getX()[0]))\n",
    "        delta=np.zeros((len(samples_packs)-1,len(samples_packs[0].getX()[0])))\n",
    "        # 迭代求解\n",
    "        max_iter=1000\n",
    "        # 设置算法的退出阈值threshold\n",
    "        threshold=0.001\n",
    "        beta1=np.ones(len(samples_packs[0].getX()[0]))\n",
    "        beta2=np.ones(len(samples_packs[0].getX()[0]))\n",
    "        for i in range(max_iter):\n",
    "            # 第一步:交替求解beta与delta\n",
    "            if i==0:\n",
    "                times.append(time.time()-start_time)\n",
    "            for j in range(max_iter):\n",
    "                beta=self.update_beta(delta,v,samples_packs)\n",
    "                #计算beta与beta2的差的2范数\n",
    "                print(np.linalg.norm(beta-beta2))\n",
    "                if np.linalg.norm(beta-beta2)<threshold:\n",
    "                    break\n",
    "                beta2=beta\n",
    "                if i==0:\n",
    "                    times.append(time.time()-start_time)\n",
    "                #对K个辅助模型分别更新其delta_k\n",
    "                for k in range(len(samples_packs)-1):\n",
    "                    delta[k]=self.update_delta_k(beta,samples_packs[k+1])\n",
    "                if i==0:\n",
    "                    times.append(time.time()-start_time)\n",
    "            print(\"**************\"+str(np.linalg.norm(beta-beta1))+\"*************\")\n",
    "            if np.linalg.norm(beta-beta1)<threshold:\n",
    "                break\n",
    "            beta1=beta\n",
    "            # 第二步：更新v\n",
    "            # 选择delta的q范数最小的L个模型，将其对应的v设为1，其余设为0。\n",
    "            # 目前选择q=2\n",
    "            if i==0:\n",
    "                times.append(time.time()-start_time)\n",
    "            v=np.zeros(len(samples_packs[1:]))\n",
    "            v[np.argsort(np.linalg.norm(delta,axis=1))[:L]]=1\n",
    "            if np.linalg.norm(v-v1)<threshold:#-?除了beta不变之外，加入了v不变的退出条件。实际上这两个退出的效果是一样的（吗？）\n",
    "                print(\"v not change\")\n",
    "                # break\n",
    "            else:\n",
    "                print(\"v change\")\n",
    "            v1=v\n",
    "            if i==0:\n",
    "                times.append(time.time()-start_time)\n",
    "        # 返回beta\n",
    "        # -?暂时不设置稀疏度-?设置了一下\n",
    "        #保留绝对值前s大个\n",
    "        # beta[np.argsort(np.abs(beta))[:-s]] = 0\n",
    "        self.params=beta\n",
    "        return beta,delta,v\n",
    "\n",
    "# 考虑后期以该类模拟不同数据的分布，对取数据加以时间限制等\n",
    "class samples_pack:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def get_n_fretures(self):\n",
    "        return len(self.X[0])\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    def getX(self):\n",
    "        return self.X\n",
    "    def getY(self):\n",
    "        return self.y\n",
    "\n",
    "# 生成样本数据\n",
    "#   \n",
    "def coef_gen(coef, cov, noise_mean, noise_var, n_samples):\n",
    "    # 生成特征\n",
    "    X = np.random.multivariate_normal(np.zeros(len(coef)), cov, n_samples)\n",
    "    # 生成噪声\n",
    "    noise = np.random.normal(noise_mean, noise_var, n_samples)\n",
    "    # 生成标签\n",
    "    y = np.dot(X, coef) + noise\n",
    "    return X, y\n",
    "\n",
    "def indep_eval(n_features,s,n_packs,n_samples):\n",
    "    coef_true = np.zeros(n_features)\n",
    "    coef_true[:s] = 0.3\n",
    "    samples_packs=[]\n",
    "    # 设定超参数：各模型回归系数、特征间的协方差矩阵、噪声的均值与方差\n",
    "    # 长度为n_features, 其中前s个为非零回归系数，后n_features-s个为零\n",
    "    #生成样本\n",
    "    for i in range(n_packs):\n",
    "        cov = np.eye(n_features)\n",
    "        delta = np.zeros(n_features)\n",
    "        #delta=e*i*0.01\n",
    "        # delta[:]=0.01*i\n",
    "        coef=coef_true+delta\n",
    "        noise_mean = 0\n",
    "        noise_var = 1\n",
    "        X, y = coef_gen(coef, cov, noise_mean, noise_var, n_samples)\n",
    "        samples_packs.append(samples_pack(X, y))\n",
    "    return samples_packs,coef_true\n",
    "\n",
    "def t11_eval(n_features,s,n_packs,n_samples,h,L):\n",
    "    coef_list=[]\n",
    "    coef_true = np.zeros(n_features)\n",
    "    coef_true[:s] = 0.3\n",
    "    # coef_list.append(coef_true)\n",
    "    samples_packs=[]\n",
    "    # 设定超参数：各模型回归系数、特征间的协方差矩阵、噪声的均值与方差\n",
    "    # 长度为n_features, 其中前s个为非零回归系数，后n_features-s个为零\n",
    "    #生成样本\n",
    "    for i in range(n_packs):\n",
    "        cov = np.eye(n_features)\n",
    "        delta = np.zeros(n_features)\n",
    "        #在0~n_features之间随机选取h个位置，将其回归系数减0.3\n",
    "        if i==0:\n",
    "            pass\n",
    "        elif i<L+1:\n",
    "            random_list=random.sample(range(n_features),h)\n",
    "            delta[random_list]=-0.1\n",
    "        else:\n",
    "            random_list=random.sample(range(n_features),12)\n",
    "            delta[random_list]=-0.5\n",
    "        coef=coef_true+delta\n",
    "        coef_list.append(coef)\n",
    "        noise_mean = 0\n",
    "        noise_var = 1\n",
    "        X, y = coef_gen(coef, cov, noise_mean, noise_var, n_samples)\n",
    "        samples_packs.append(samples_pack(X, y))\n",
    "    return samples_packs,coef_true,coef_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample packs generated\n",
      "2.9469601412128954\n",
      "0.0\n",
      "**************2.9469601412128954*************\n",
      "v change\n",
      "0.0006657104750392897\n",
      "**************0.0006657104750392897*************\n",
      "SSE: 0.4717429051310348\n"
     ]
    }
   ],
   "source": [
    "n_features=16\n",
    "n_samples=100\n",
    "n_packs=101\n",
    "s=16\n",
    "model=Our_method(n_features,s,1)\n",
    "t_lasso=T_lasso(n_features,s,1)\n",
    "\n",
    "result_list=[]\n",
    "SSE_list=[]\n",
    "h=6\n",
    "L=16\n",
    "sample_packs,coef_true,coef_list=t11_eval(n_features,s,n_packs,n_samples,h,L)\n",
    "print(\"sample packs generated\")\n",
    "output=model.fit(sample_packs,s,L,coef_list)\n",
    "beta,delta,v=output\n",
    "SSE=np.linalg.norm(beta-coef_true)\n",
    "result_list.append(output)\n",
    "lasso_SSE=np.linalg.norm(t_lasso.fit(sample_packs)-coef_true)\n",
    "SSE_list.append(SSE)\n",
    "print(\"SSE:\",SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4927701208875264"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40471725, 0.21263661, 0.18483892, 0.32908529, 0.45259054,\n",
       "       0.32740729, 0.35977307, 0.3232083 , 0.28076739, 0.15535504,\n",
       "       0.3053004 , 0.14759274, 0.4665613 , 0.19078719, 0.14950032,\n",
       "       0.0658624 ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.13934474,  0.21184232,  0.25875687, ...,  0.11748285,\n",
       "         0.2343149 ,  0.20669662],\n",
       "       [-0.35431447, -0.00808049,  0.16538487, ...,  0.04234074,\n",
       "         0.1114724 ,  0.37219735],\n",
       "       [-0.16042919,  0.06716898,  0.14965961, ...,  0.10314599,\n",
       "        -0.03401509,  0.2677073 ],\n",
       "       ...,\n",
       "       [-0.6497216 , -0.39531776, -0.3774674 , ..., -0.38143353,\n",
       "        -0.40768611, -0.18989333],\n",
       "       [-0.59832934,  0.21353842, -0.44001936, ..., -0.31743542,\n",
       "         0.22960617, -0.31351506],\n",
       "       [-0.56349051, -0.41405554,  0.08854444, ..., -0.33266939,\n",
       "        -0.30429163, -0.37052959]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
