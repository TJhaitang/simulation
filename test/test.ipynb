{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluator import *\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from abc import abstractmethod\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[1,2,3,4,5,6,7,8,9]\n",
    "x[12:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class estiminator:\n",
    "    def __init__(self,n_features):\n",
    "        self.params=np.zeros(n_features)\n",
    "        self.n_features=n_features\n",
    "    \n",
    "    @abstractmethod\n",
    "    def fit(self, samples_packs,s,L):\n",
    "        pass\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "\n",
    "class our_method(estiminator):\n",
    "    def __init__(self, n_features):\n",
    "        super(our_method, self).__init__(n_features)\n",
    "      \n",
    "    #这个方法没有用到，目的是方便使用梯度下降等方法，将更新方法放到模型里面去  \n",
    "    def likelihood(self, beta, delta, samples_pack):\n",
    "        beta=beta+delta\n",
    "        X=samples_pack.getX()\n",
    "        y=samples_pack.getY()\n",
    "        # 似然函数为高斯分布\n",
    "        return -np.sum((y-np.dot(X,beta))**2)\n",
    "    \n",
    "    #更新beta\n",
    "    #输入：delta:辅助模型与目标模型的回归系数差矩阵，v:辅助模型是否被选择的向量，samples_packs:样本数据\n",
    "    # 优化问题：argmax_{beta} l_0(beta)+sum_{k=1}^{K}(l_k(beta,delta[k])-lambda*||delta||_2)*v[k]\n",
    "    def update_beta(self, delta, v, samples_packs):#加入了l2正则-?\n",
    "        # 对于线性模型，该问题有显式解\n",
    "        # 该显式解为beta=(x0^T*x0+sum_{k=1}^{K}v[k]*xk^T*xk-lambda*E)^{-1}*(x0^T*y0+sum_{k=1}^{K}v[k]*xk^T*yk-sum_{k=1}^{K}v[k]*xk^T*xk*delta[k])\n",
    "        # x0,y0为目标模型的样本数据\n",
    "        # xk,yk为第k个辅助模型的样本数据\n",
    "        \n",
    "        #mat1=x0^T*x0+sum_{k=1}^{K}v[k]*xk^T*xk-lambda*E\n",
    "        lamb=0.001\n",
    "        mat1=np.dot(samples_packs[0].getX().T,samples_packs[0].getX())\n",
    "        mat1-=lamb*np.eye(len(samples_packs[0].getX()[0]))\n",
    "        for i in range(len(samples_packs)-1):\n",
    "            if v[i]==1:\n",
    "                mat1+=np.dot(samples_packs[i+1].getX().T,samples_packs[i+1].getX())\n",
    "        #mat2=x0^T*y0+sum_{k=1}^{K}v[k]*xk^T*yk\n",
    "        mat2=np.dot(samples_packs[0].getX().T,samples_packs[0].getY())\n",
    "        for i in range(len(samples_packs)-1):\n",
    "            if v[i]==1:\n",
    "                mat2+=np.dot(samples_packs[i+1].getX().T,samples_packs[i+1].getY())\n",
    "        #mat3=sum_{k=1}^{K}v[k]*xk^T*xk*delta[k]\n",
    "        mat3=np.zeros(len(samples_packs[0].getX()[0]))\n",
    "        for i in range(len(samples_packs)-1):\n",
    "            if v[i]==1:\n",
    "                mat3+=np.dot(samples_packs[i+1].getX().T,np.dot(samples_packs[i+1].getX(),delta[i]))\n",
    "        beta=np.dot(np.linalg.inv(mat1),mat2-mat3)\n",
    "        return beta\n",
    "    \n",
    "    #更新delta\n",
    "    #输入：beta:当前beta，sample_pack:该模型的样本数据\n",
    "    #输出：更新后的delta_k\n",
    "    def update_delta_k(self,beta,sample_pack):#修改为2范数不平方    \n",
    "        # 对于线性模型，这里是delta的岭回归解-?关于delta的惩罚项，ppt里面是2范数，这里先用2范数的平方了\n",
    "        # 该显示解delta=(X^T*X-lambda*I)^{-1}*X^T*(y-X*beta)\n",
    "        # 关于lambda的取值问题该怎么解决呢？-?这里先假定lambda=1\n",
    "        lamb=0.001\n",
    "        X=sample_pack.getX()\n",
    "        y=sample_pack.getY()\n",
    "        delta=np.dot(np.linalg.inv(np.dot(X.T,X)-lamb*np.eye(len(X[0]))),np.dot(X.T,y)-np.dot(X.T,np.dot(X,beta)))\n",
    "        return delta\n",
    "        \n",
    "    \n",
    "    # 非iid分布式迁移学习与数据源选择\n",
    "    # delta[k]=beta[k]-beta[0] 为第k个辅助模型与目标模型的回归系数差\n",
    "    # 上述参数均为n_features维向量\n",
    "    # v[k]属于{0,1},为第k个辅助模型是否被选择\n",
    "    # 优化问题：argmax_{beta,delta[k],v[k]} l_0(beta)+sum_{k=1}^{K}(l_k(beta,delta[k])-lambda*||delta||_2)*v[k]\n",
    "    # s.t. ||v||_0=L\n",
    "    # l_k为模型的似然函数，当前模型为线性模型，似然函数为高斯分布\n",
    "    # 使用两步迭代算法求解\n",
    "    # 第一步：固定v[k]，求解beta[0],delta[k]\n",
    "    # 求解beta与delta时也使用两步迭代算法\n",
    "    # 第二步：固定beta[0],delta[k]，求解v[k]\n",
    "    # 重复以上两步直到收敛（或达到最大迭代次数）\n",
    "    # -?没有设置收敛条件，目前仅仅设置了最大迭代次数\n",
    "    # 输入：samples_packs:样本数据，s:目标模型稀疏度，L:选定的辅助模型个数\n",
    "    def fit(self, samples_packs,s,L):\n",
    "        #如果model_num==0,则直接使用目标模型的样本数据进行lasso估计\n",
    "        model_num=len(samples_packs)-1\n",
    "        if model_num==0:\n",
    "            lasso=Lasso(alpha=0.01)\n",
    "            lasso.fit(samples_packs[0].getX(),samples_packs[0].getY())\n",
    "            #保留绝对值前s大个-?有意义吗？\n",
    "            self.params=lasso.coef_\n",
    "            return lasso.coef_,[],[],[]\n",
    "        # 初始化参数\n",
    "        # -?第一次迭代时使用全部模型,v=[1,1,1,1,...]\n",
    "        #计算程序运行时间\n",
    "        start_time=time.time()\n",
    "        times=[]\n",
    "        times.append(time.time()-start_time)\n",
    "        \n",
    "        v=np.ones(len(samples_packs)-1)\n",
    "        # beta为目标模型的回归系数\n",
    "        beta=np.zeros(len(samples_packs[0].getX()[0]))\n",
    "        delta=np.zeros((len(samples_packs)-1,len(samples_packs[0].getX()[0])))\n",
    "        # 迭代求解\n",
    "        max_iter=5\n",
    "        # 设置算法的退出阈值threshold\n",
    "        threshold=0.001\n",
    "        beta1=np.ones(len(samples_packs[0].getX()[0]))\n",
    "        beta2=np.ones(len(samples_packs[0].getX()[0]))\n",
    "        for i in range(max_iter):\n",
    "            time.sleep(0.5)\n",
    "            # 第一步:交替求解beta与delta\n",
    "            if i==0:\n",
    "                times.append(time.time()-start_time)\n",
    "            for j in range(max_iter):\n",
    "                beta=self.update_beta(delta,v,samples_packs)\n",
    "                # print(beta)\n",
    "                #计算beta与beta2的差的2范数\n",
    "                if np.linalg.norm(beta-beta2)<threshold:\n",
    "                    break\n",
    "                beta2=beta\n",
    "                if i==0:\n",
    "                    times.append(time.time()-start_time)\n",
    "                #对K个辅助模型分别更新其delta_k\n",
    "                for k in range(len(samples_packs)-1):\n",
    "                    delta[k]=self.update_delta_k(beta,samples_packs[k+1])\n",
    "                    # print(delta[k])\n",
    "                if i==0:\n",
    "                    times.append(time.time()-start_time)\n",
    "            if np.linalg.norm(beta-beta1)<threshold:\n",
    "                break\n",
    "            beta1=beta\n",
    "            # 第二步：更新v\n",
    "            # 选择delta的q范数最小的L个模型，将其对应的v设为1，其余设为0。\n",
    "            # 目前选择q=2\n",
    "            if i==0:\n",
    "                times.append(time.time()-start_time)\n",
    "            v=np.zeros(len(samples_packs[1:]))\n",
    "            v[np.argsort(np.linalg.norm(delta,axis=1))[:L]]=1\n",
    "            print(v)\n",
    "            if i==0:\n",
    "                times.append(time.time()-start_time)\n",
    "        # 返回beta\n",
    "        # -?暂时不设置稀疏度-?设置了一下\n",
    "        #保留绝对值前s大个\n",
    "        # beta[np.argsort(np.abs(beta))[:-s]] = 0\n",
    "        self.params=beta\n",
    "        return beta,delta,v,times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3.4439532936552565e+70 5.956866502761841\n"
     ]
    }
   ],
   "source": [
    "n_features=500\n",
    "n_samples=100\n",
    "n_packs=21\n",
    "s=16\n",
    "h=6\n",
    "L=4\n",
    "eval=evaluator(n_features, n_packs, n_samples, s, L)\n",
    "_,model_sse,model_time=eval.t11_eval(our_method(n_features),h)\n",
    "print(model_sse,model_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
